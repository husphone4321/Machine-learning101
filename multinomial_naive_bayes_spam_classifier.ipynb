{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada64cac",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes for Spam Email Classification\n",
    "This notebook demonstrates how to use the Multinomial Naive Bayes algorithm to classify emails as spam or normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e212051f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1672980161.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    The goal of this notebook is to classify emails as either \"spam\" or \"normal\" using the Multinomial Naive Bayes algorithm.\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Problem Setup\n",
    "\n",
    "The goal of this notebook is to classify emails as either \"spam\" or \"normal\" using the Multinomial Naive Bayes algorithm. \n",
    "\n",
    "### Key Steps:\n",
    "1. **Dataset Preparation**:\n",
    "    - A dataset of 10 emails is created, where each email is labeled as \"spam\" or \"normal\".\n",
    "\n",
    "2. **Feature Extraction**:\n",
    "    - The text data is converted into numerical features using `CountVectorizer`.\n",
    "\n",
    "3. **Model Training**:\n",
    "    - The Multinomial Naive Bayes model is trained on the extracted features and labels.\n",
    "\n",
    "4. **Evaluation**:\n",
    "    - The models performance is evaluated using accuracy and a classification report.\n",
    "\n",
    "5. **Prediction**:\n",
    "    - The trained model is used to classify new, unseen emails.\n",
    "\n",
    "This setup demonstrates how text classification can be performed using machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41662b7b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b56eef94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cb49b29",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "We will use libraries such as `pandas`, `sklearn`, and `numpy` for data manipulation, model building, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51031afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17734b8b",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset\n",
    "We will use a dataset containing labeled emails as spam or normal. The dataset should have two columns: `text` (email content) and `label` (spam or normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b982c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text   label\n",
      "0  Congratulations! You've won a $1,000 gift card...    spam\n",
      "1        Hi, can we schedule a meeting for tomorrow?  normal\n",
      "2  Exclusive offer just for you. Buy now and save...    spam\n",
      "3  Don't miss out on this opportunity to earn mon...    spam\n",
      "4           Hello, I hope this email finds you well.  normal\n",
      "5  Win a free vacation to the Bahamas! Click now ...    spam\n",
      "6  Limited time offer! Get 70% off on all product...    spam\n",
      "7  Hey, just wanted to check in and see how you'r...  normal\n",
      "8  Can you send me the report by the end of the d...  normal\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataset\n",
    "data = {\n",
    "\t'text': [\n",
    "\t\t\"Congratulations! You've won a $1,000 gift card. Click here to claim your prize.\",\n",
    "\t\t\"Hi, can we schedule a meeting for tomorrow?\",\n",
    "\t\t\"Exclusive offer just for you. Buy now and save 50%.\",\n",
    "\t\t\"Don't miss out on this opportunity to earn money from home.\",\n",
    "\t\t\"Hello, I hope this email finds you well.\",\n",
    "          \"Win a free vacation to the Bahamas! Click now to claim your prize.\",\n",
    "        \"Limited time offer! Get 70% off on all products. Shop today!\",\n",
    "        \"Hey, just wanted to check in and see how you're doing.\",\n",
    "        \"Can you send me the report by the end of the day? Thanks!\"\n",
    "\t],\n",
    "\t'label': ['spam', 'normal', 'spam', 'spam', 'normal','spam', 'spam', 'normal', 'normal']\n",
    "}\n",
    "\n",
    "# Convert the sample data into a DataFrame\n",
    "emails = pd.DataFrame(data)\n",
    "\n",
    "# Display all rows of the dataset\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Display all columns of the dataset\n",
    "\n",
    "print(emails)\n",
    "\n",
    "# Check for missing values\n",
    "print(emails.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a7032c",
   "metadata": {},
   "source": [
    "## 3. Preprocess the Data\n",
    "Convert the text data into numerical features using `CountVectorizer` and split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a871385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to numerical features\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(emails['text'])\n",
    "\n",
    "# Encode labels (spam = 1, normal = 0)\n",
    "y = emails['label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d11e9",
   "metadata": {},
   "source": [
    "visualize contents of all the training mails and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8ffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text   label\n",
      "5  Win a free vacation to the Bahamas! Click now ...    spam\n",
      "0  Congratulations! You've won a $1,000 gift card...    spam\n",
      "8  Can you send me the report by the end of the d...  normal\n",
      "2  Exclusive offer just for you. Buy now and save...    spam\n",
      "4           Hello, I hope this email finds you well.  normal\n",
      "3  Don't miss out on this opportunity to earn mon...    spam\n",
      "6  Limited time offer! Get 70% off on all product...    spam\n"
     ]
    }
   ],
   "source": [
    "# Extract the training set emails using the indices of y_train\n",
    "training_emails = emails.loc[y_train.index]\n",
    "\n",
    "# Display the contents of the training emails\n",
    "print(training_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcba7e5",
   "metadata": {},
   "source": [
    "visualize contents of all the testing mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c43b644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text   label\n",
      "7  Hey, just wanted to check in and see how you'r...  normal\n",
      "1        Hi, can we schedule a meeting for tomorrow?  normal\n"
     ]
    }
   ],
   "source": [
    "# Extract the testing set emails using the indices of y_test\n",
    "testing_emails = emails.loc[y_test.index]\n",
    "\n",
    "# Display the contents of the testing emails\n",
    "print(testing_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b81c6c",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a29d0",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2880109c",
   "metadata": {},
   "source": [
    "## 4. Train the Multinomial Naive Bayes Model\n",
    "Fit the model to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0c0a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55bb6c1b",
   "metadata": {},
   "source": [
    "## How the Multinomial Naive Bayes Model is Trained\n",
    "\n",
    "The Multinomial Naive Bayes model is trained using the following steps:\n",
    "\n",
    "1. **Feature Extraction**:\n",
    "    - The text data is converted into numerical features using the `CountVectorizer`. This creates a matrix where each row represents an email, and each column represents the count of a specific word in that email.\n",
    "\n",
    "2. **Label Encoding**:\n",
    "    - The labels (spam or normal) are encoded as binary values: `1` for spam and `0` for normal.\n",
    "\n",
    "3. **Training the Model**:\n",
    "    - The model calculates the probabilities required for classification:\n",
    "        - **Prior Probabilities**: The probability of each class (spam or normal) in the training data.\n",
    "        - **Conditional Probabilities**: The probability of each word given a class, computed using Laplace smoothing to handle words that may not appear in a particular class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963f7c9",
   "metadata": {},
   "source": [
    "\n",
    "## Computing Prior Probabilities for Each Class\n",
    "\n",
    "The prior probability for each class is the proportion of samples belonging to that class in the training dataset. It is calculated as:\n",
    "\n",
    "$$\n",
    "P(c) = \\frac{\\text{Number of Samples in Class } c}{\\text{Total Number of Samples}}\n",
    "$$\n",
    "\n",
    "### Steps to Compute Prior Probabilities:\n",
    "1. **Count the Samples in Each Class**:\n",
    "    - Count the number of training samples labeled as \"spam\" and \"normal\".\n",
    "\n",
    "2. **Divide by Total Samples**:\n",
    "    - Divide the count of samples in each class by the total number of training samples.\n",
    "\n",
    "### Example from the Notebook:\n",
    "- Total training samples: 7\n",
    "- Samples in \"normal\" class (label = 0): 2\n",
    "- Samples in \"spam\" class (label = 1): 5\n",
    "\n",
    "The prior probabilities are:\n",
    "- For \"normal\" class:\n",
    "  $$\n",
    "  P(\\text{normal}) = \\frac{2}{7} \\approx 0.2857\n",
    "  $$\n",
    "\n",
    "- For \"spam\" class:\n",
    "  $$\n",
    "  P(\\text{spam}) = \\frac{5}{7} \\approx 0.7143\n",
    "  $$\n",
    "\n",
    "These values are stored in the variable `class_prior_probabilities` as:\n",
    "```python\n",
    "array([0.28571429, 0.71428571])\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f26efb",
   "metadata": {},
   "source": [
    "## computing Class Conditional Probabilities\n",
    "\n",
    "The class conditional probability for each word is computed using the Multinomial Naive Bayes formula. Here's how it works:\n",
    "\n",
    "1. **Count the Occurrences of Each Word in Each Class**:\n",
    "    - For each word in the vocabulary, count how many times it appears in emails labeled as \"spam\" and \"normal\".\n",
    "\n",
    "2. **Add Smoothing**:\n",
    "    - To avoid zero probabilities for words that do not appear in a particular class, Laplace smoothing is applied. This involves adding 1 to the count of each word and adding the total number of unique words (vocabulary size) to the denominator.\n",
    "\n",
    "3. **Compute the Probability**:\n",
    "    - The conditional probability of a word $w$ given a class $c$ is calculated as:\n",
    "     $$\n",
    "      P(w|c) = \\frac{\\text{Count}(w, c) }{\\text{Total Words in Class } c }\n",
    "\n",
    "      $$\n",
    "\n",
    " $$\n",
    "      P(w|c) = \\frac{\\text{Count}(w, c) + 1}{\\text{Total Words in Class } c + \\text{Vocabulary Size}}      $$\n",
    "\n",
    "\n",
    "Here:\n",
    "\n",
    " $\\text{Count}(w, c)$ is the number of times the word $w$ appears in emails of class $c$.\n",
    "      - $\\text{Total Words in Class } c$ is the total count of all words in emails of class $c$.\n",
    "      - $\\text{Vocabulary Size}$ is the total number of unique words in the dataset.\n",
    "\n",
    "4. **Log Transformation**:\n",
    "    - To prevent numerical underflow during multiplication of probabilities, the logarithm of the probabilities is often used. This is stored in `model.feature_log_prob_`.\n",
    "\n",
    "5. **Convert Log Probabilities to Conditional Probabilities**:\n",
    "    - The log probabilities can be exponentiated to get the actual conditional probabilities:\n",
    "      $$\n",
    "      P(w|c) = \\exp(\\text{log}(P(w|c)))\n",
    "      $$\n",
    "\n",
    "This process ensures that the model can compute the likelihood of an email belonging to a class based on the words it contains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397e0a3",
   "metadata": {},
   "source": [
    "\n",
    "4. **Optimization**:\n",
    "    - The model optimizes the parameters by maximizing the likelihood of the training data under the Naive Bayes assumption (features are conditionally independent given the class).\n",
    "\n",
    "5. **Model Storage**:\n",
    "    - The trained model stores the log probabilities of each word for each class (`model.feature_log_prob_`) and the prior probabilities of each class (`model.class_log_prior_`).\n",
    "\n",
    "This process ensures that the model can efficiently classify new emails based on the learned probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0273a2f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prior probabilities: [0.28571429 0.71428571]\n",
      "\n",
      "Number of training samples: 7\n",
      "Number of training samples in each class: [2 5]\n",
      "\n",
      "Total words in normal mails: 32\n",
      "Total words in spams: 45\n",
      "Vocabulary size: 73\n",
      "Unique words: 73\n",
      "\n",
      "Word 1: 000\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 0\n",
      "Total count in spam mails: 1\n",
      "\n",
      "Word 2: 50\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 0\n",
      "Total count in spam mails: 1\n",
      "\n",
      "Word 3: 70\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 0\n",
      "Total count in spam mails: 1\n",
      "\n",
      "Word 4: all\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 0\n",
      "Total count in spam mails: 1\n",
      "\n",
      "Word 5: and\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 0\n",
      "Total count in spam mails: 1\n",
      "\n",
      "Word 6: bahamas\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 0\n",
      "Total count in spam mails: 1\n",
      "\n",
      "Word 7: buy\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 0\n",
      "Total count in spam mails: 1\n",
      "\n",
      "Word 8: by\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 1\n",
      "Total count in spam mails: 0\n",
      "\n",
      "Word 9: can\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 1\n",
      "Total count in spam mails: 0\n",
      "\n",
      "Word 10: card\n",
      "Count in each mail: 1\n",
      "Total count in normal mails: 0\n",
      "Total count in spam mails: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Get the feature names (words) from the vectorizer\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the word count matrix to an array for easier interpretation\n",
    "word_count_matrix = X_train.toarray()\n",
    "\n",
    "#compute and print class prior probabilities\n",
    "class_prior_probabilities = np.bincount(y_train) / len(y_train)\n",
    "print(f\"Class prior probabilities: {class_prior_probabilities}\")\n",
    "print()\n",
    "print(f\"Number of training samples: {len(y_train)}\")\n",
    "print(f\"Number of training samples in each class: {np.bincount(y_train)}\")\n",
    "print()\n",
    "\n",
    "# print the number of total words and  in normal mails and in spams\n",
    "print(f\"Total words in normal mails: {np.sum(word_count_matrix[:, :len(feature_names)//2])}\")\n",
    "print(f\"Total words in spams: {np.sum(word_count_matrix[:, len(feature_names)//2:])}\")\n",
    "\n",
    "#print the number of unique words(vocab size) which will be used for #laplacian smoothing\n",
    "print(f\"Vocabulary size: {len(feature_names)}\")\n",
    "print(f\"Unique words: {len(np.unique(feature_names))}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# for each  word , print its count in each mail in the training set and its total count in normal mails and in spam mails\n",
    "for i in range(10):\n",
    "    word = feature_names[i]\n",
    "    print(f\"Word {i+1}: {word}\")\n",
    "    print(f\"Count in each mail: {word_count_matrix[:, i].sum()}\")\n",
    "    print(f\"Total count in normal mails: {word_count_matrix[y_train == 0, i].sum()}\")\n",
    "    print(f\"Total count in spam mails: {word_count_matrix[y_train == 1, i].sum()}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85db9675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4845792",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76b0228b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "922af8f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "290e987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class normal mail:\n",
      "000: 0.0108\n",
      "50: 0.0108\n",
      "70: 0.0108\n",
      "all: 0.0108\n",
      "and: 0.0108\n",
      "bahamas: 0.0108\n",
      "buy: 0.0108\n",
      "by: 0.0215\n",
      "can: 0.0215\n",
      "card: 0.0108\n",
      "check: 0.0108\n",
      "claim: 0.0108\n",
      "click: 0.0108\n",
      "congratulations: 0.0108\n",
      "day: 0.0215\n",
      "doing: 0.0108\n",
      "don: 0.0108\n",
      "earn: 0.0108\n",
      "email: 0.0215\n",
      "end: 0.0215\n",
      "exclusive: 0.0108\n",
      "finds: 0.0215\n",
      "for: 0.0108\n",
      "free: 0.0108\n",
      "from: 0.0108\n",
      "get: 0.0108\n",
      "gift: 0.0108\n",
      "hello: 0.0215\n",
      "here: 0.0108\n",
      "hey: 0.0108\n",
      "hi: 0.0108\n",
      "home: 0.0108\n",
      "hope: 0.0215\n",
      "how: 0.0108\n",
      "in: 0.0108\n",
      "just: 0.0108\n",
      "limited: 0.0108\n",
      "me: 0.0215\n",
      "meeting: 0.0108\n",
      "miss: 0.0108\n",
      "money: 0.0108\n",
      "now: 0.0108\n",
      "of: 0.0215\n",
      "off: 0.0108\n",
      "offer: 0.0108\n",
      "on: 0.0108\n",
      "opportunity: 0.0108\n",
      "out: 0.0108\n",
      "prize: 0.0108\n",
      "products: 0.0108\n",
      "re: 0.0108\n",
      "report: 0.0215\n",
      "save: 0.0108\n",
      "schedule: 0.0108\n",
      "see: 0.0108\n",
      "send: 0.0215\n",
      "shop: 0.0108\n",
      "thanks: 0.0215\n",
      "the: 0.0430\n",
      "this: 0.0215\n",
      "time: 0.0108\n",
      "to: 0.0108\n",
      "today: 0.0108\n",
      "tomorrow: 0.0108\n",
      "vacation: 0.0108\n",
      "ve: 0.0108\n",
      "wanted: 0.0108\n",
      "we: 0.0108\n",
      "well: 0.0215\n",
      "win: 0.0108\n",
      "won: 0.0108\n",
      "you: 0.0323\n",
      "your: 0.0108\n",
      "\n",
      "Class spam mail:\n",
      "000: 0.0154\n",
      "50: 0.0154\n",
      "70: 0.0154\n",
      "all: 0.0154\n",
      "and: 0.0154\n",
      "bahamas: 0.0154\n",
      "buy: 0.0154\n",
      "by: 0.0077\n",
      "can: 0.0077\n",
      "card: 0.0154\n",
      "check: 0.0077\n",
      "claim: 0.0231\n",
      "click: 0.0231\n",
      "congratulations: 0.0154\n",
      "day: 0.0077\n",
      "doing: 0.0077\n",
      "don: 0.0154\n",
      "earn: 0.0154\n",
      "email: 0.0077\n",
      "end: 0.0077\n",
      "exclusive: 0.0154\n",
      "finds: 0.0077\n",
      "for: 0.0154\n",
      "free: 0.0154\n",
      "from: 0.0154\n",
      "get: 0.0154\n",
      "gift: 0.0154\n",
      "hello: 0.0077\n",
      "here: 0.0154\n",
      "hey: 0.0077\n",
      "hi: 0.0077\n",
      "home: 0.0154\n",
      "hope: 0.0077\n",
      "how: 0.0077\n",
      "in: 0.0077\n",
      "just: 0.0154\n",
      "limited: 0.0154\n",
      "me: 0.0077\n",
      "meeting: 0.0077\n",
      "miss: 0.0154\n",
      "money: 0.0154\n",
      "now: 0.0231\n",
      "of: 0.0077\n",
      "off: 0.0154\n",
      "offer: 0.0231\n",
      "on: 0.0231\n",
      "opportunity: 0.0154\n",
      "out: 0.0154\n",
      "prize: 0.0231\n",
      "products: 0.0154\n",
      "re: 0.0077\n",
      "report: 0.0077\n",
      "save: 0.0154\n",
      "schedule: 0.0077\n",
      "see: 0.0077\n",
      "send: 0.0077\n",
      "shop: 0.0154\n",
      "thanks: 0.0077\n",
      "the: 0.0154\n",
      "this: 0.0154\n",
      "time: 0.0154\n",
      "to: 0.0385\n",
      "today: 0.0154\n",
      "tomorrow: 0.0077\n",
      "vacation: 0.0154\n",
      "ve: 0.0154\n",
      "wanted: 0.0077\n",
      "we: 0.0077\n",
      "well: 0.0077\n",
      "win: 0.0154\n",
      "won: 0.0154\n",
      "you: 0.0231\n",
      "your: 0.0231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Get the feature names (words) from the vectorizer\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get the log probabilities for each word in each class\n",
    "log_probabilities = model.feature_log_prob_\n",
    "\n",
    "#convert log probabilities to conditional probabilities\n",
    "conditional_probabilities = [np.exp(log_prob) for log_prob in log_probabilities]\n",
    "\n",
    "# Print the conditional probabilities for each word for each class\n",
    "classname=['normal mail', 'spam mail']\n",
    "for i, class_probabilities in enumerate(conditional_probabilities):\n",
    "    print(f\"Class {classname[i]}:\")\n",
    "    for word, prob in zip(feature_names, class_probabilities):\n",
    "        print(f\"{word}: {prob:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8176f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "#fit the model to the training data\n",
    "# Make predictions on the test set\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef152a3",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model\n",
    "Evaluate the model's performance on the test data using accuracy and a classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e247abe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b8edfae",
   "metadata": {},
   "source": [
    "## How the Model Classifies a New Email\n",
    "\n",
    "\n",
    "\n",
    "1. **Feature Extraction**:\n",
    "    - The email text is transformed into numerical features using the same `CountVectorizer` that was used during training. This ensures consistency in the feature representation.\n",
    "\n",
    "2. **Compute class posteria Probabilities**:\n",
    "    - The model calculates the log probabilities for each class (spam or normal) based on the words present in the new test email\n",
    "\n",
    "3. **Apply Naive Bayes Formula**:\n",
    "    - The model computes the likelihood of the email belonging to each class using the Naive Bayes formula:\n",
    "      $$\n",
    "      \\text{Log Likelihood}(c) = \\text{Log Prior}(c) + \\sum_{w \\in \\text{Email}} \\text{Log}(P(w|c))\n",
    "      $$\n",
    "\n",
    "  $$\n",
    "      \\text{ Likelihood}(c) = \\text{Prior}(c) * \\prod_{w \\in \\text{Email}} \\text{}(P(w|c))\n",
    "      $$\n",
    "\n",
    "      \n",
    "      \n",
    " Here, \n",
    "       \n",
    "$c$ is the class (spam or normal), and $P(w|c)$ is the conditional probability of word $w$ given class $c$.\n",
    "\n",
    "4. **Class Prediction**:\n",
    "    - The class with the highest likelihood is selected as the predicted class for the email.\n",
    "\n",
    "5. **Output**:\n",
    "    - The model outputs the predicted label (`spam` or `normal`) for the email.\n",
    "\n",
    "This process ensures that the model uses the learned probabilities to make accurate predictions for new, unseen emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hey, just wanted to check in and see how you're doing.\n",
      "Label: normal\n",
      "Predicted: normal\n",
      "\n",
      "Original: Hi, can we schedule a meeting for tomorrow?\n",
      "Label: normal\n",
      "Predicted: normal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# print the original content and label for each mail in test set and its predicted labels\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Original: {testing_emails.iloc[i]['text']}\")\n",
    "    print(f\"Label: {testing_emails.iloc[i]['label']}\")\n",
    "    print(f\"Predicted: {'spam' if y_pred[i] == 1 else 'normal'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b46a2b",
   "metadata": {},
   "source": [
    "## 6. Test with New Emails\n",
    "Use the trained model to classify new email samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e07f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: Congratulations! You've won a $1,000 gift card. Click here to claim your prize.\n",
      "Prediction: Spam\n",
      "\n",
      "Email: Hi, can we schedule a meeting for tomorrow?\n",
      "Prediction: Normal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with new email samples\n",
    "new_emails = [\n",
    "    \"Congratulations! You've won a $1,000 gift card. Click here to claim your prize.\",\n",
    "    \"Hi, can we schedule a meeting for tomorrow?\"\n",
    "]\n",
    "\n",
    "# Transform the new emails using the same vectorizer\n",
    "new_emails_transformed = vectorizer.transform(new_emails)\n",
    "\n",
    "# Predict labels for the new emails\n",
    "predictions = model.predict(new_emails_transformed)\n",
    "\n",
    "# Display predictions\n",
    "for email, label in zip(new_emails, predictions):\n",
    "    print(f\"Email: {email}\\nPrediction: {'Spam' if label == 1 else 'Normal'}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830af447",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
